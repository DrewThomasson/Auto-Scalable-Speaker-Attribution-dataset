wandb_version: 1

_wandb:
  desc: null
  value:
    python_version: 3.10.13
    cli_version: 0.16.0
    framework: huggingface
    huggingface_version: 4.30.0
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1710731914.929618
    t:
      1:
      - 1
      - 5
      - 11
      - 33
      - 49
      - 53
      - 55
      - 71
      - 105
      2:
      - 1
      - 5
      - 11
      - 33
      - 49
      - 53
      - 55
      - 71
      - 105
      3:
      - 7
      - 23
      4: 3.10.13
      5: 0.16.0
      6: 4.30.0
      8:
      - 5
      13: linux-x86_64
    m:
    - 1: train/global_step
      6:
      - 3
vocab_size:
  desc: null
  value: 50257
n_positions:
  desc: null
  value: 1024
n_embd:
  desc: null
  value: 768
n_layer:
  desc: null
  value: 6
n_head:
  desc: null
  value: 12
n_inner:
  desc: null
  value: null
activation_function:
  desc: null
  value: gelu_new
resid_pdrop:
  desc: null
  value: 0.1
embd_pdrop:
  desc: null
  value: 0.1
attn_pdrop:
  desc: null
  value: 0.1
layer_norm_epsilon:
  desc: null
  value: 1.0e-05
initializer_range:
  desc: null
  value: 0.02
summary_type:
  desc: null
  value: cls_index
summary_use_proj:
  desc: null
  value: true
summary_activation:
  desc: null
  value: null
summary_first_dropout:
  desc: null
  value: 0.1
summary_proj_to_labels:
  desc: null
  value: true
scale_attn_weights:
  desc: null
  value: true
use_cache:
  desc: null
  value: true
scale_attn_by_inverse_layer_idx:
  desc: null
  value: false
reorder_and_upcast_attn:
  desc: null
  value: false
bos_token_id:
  desc: null
  value: 50256
eos_token_id:
  desc: null
  value: 50256
return_dict:
  desc: null
  value: true
output_hidden_states:
  desc: null
  value: false
output_attentions:
  desc: null
  value: false
torchscript:
  desc: null
  value: false
torch_dtype:
  desc: null
  value: null
use_bfloat16:
  desc: null
  value: false
tf_legacy_loss:
  desc: null
  value: false
pruned_heads:
  desc: null
  value: {}
tie_word_embeddings:
  desc: null
  value: true
is_encoder_decoder:
  desc: null
  value: false
is_decoder:
  desc: null
  value: false
cross_attention_hidden_size:
  desc: null
  value: null
add_cross_attention:
  desc: null
  value: false
tie_encoder_decoder:
  desc: null
  value: false
max_length:
  desc: null
  value: 20
min_length:
  desc: null
  value: 0
do_sample:
  desc: null
  value: false
early_stopping:
  desc: null
  value: false
num_beams:
  desc: null
  value: 1
num_beam_groups:
  desc: null
  value: 1
diversity_penalty:
  desc: null
  value: 0.0
temperature:
  desc: null
  value: 1.0
top_k:
  desc: null
  value: 50
top_p:
  desc: null
  value: 1.0
typical_p:
  desc: null
  value: 1.0
repetition_penalty:
  desc: null
  value: 1.0
length_penalty:
  desc: null
  value: 1.0
no_repeat_ngram_size:
  desc: null
  value: 0
encoder_no_repeat_ngram_size:
  desc: null
  value: 0
bad_words_ids:
  desc: null
  value: null
num_return_sequences:
  desc: null
  value: 1
chunk_size_feed_forward:
  desc: null
  value: 0
output_scores:
  desc: null
  value: false
return_dict_in_generate:
  desc: null
  value: false
forced_bos_token_id:
  desc: null
  value: null
forced_eos_token_id:
  desc: null
  value: null
remove_invalid_values:
  desc: null
  value: false
exponential_decay_length_penalty:
  desc: null
  value: null
suppress_tokens:
  desc: null
  value: null
begin_suppress_tokens:
  desc: null
  value: null
architectures:
  desc: null
  value:
  - GPT2LMHeadModel
finetuning_task:
  desc: null
  value: null
id2label:
  desc: null
  value:
    '0': LABEL_0
    '1': LABEL_1
    '2': LABEL_2
    '3': LABEL_3
    '4': LABEL_4
    '5': LABEL_5
    '6': LABEL_6
    '7': LABEL_7
    '8': LABEL_8
    '9': LABEL_9
    '10': LABEL_10
    '11': LABEL_11
    '12': LABEL_12
    '13': LABEL_13
    '14': LABEL_14
    '15': LABEL_15
    '16': LABEL_16
    '17': LABEL_17
    '18': LABEL_18
    '19': LABEL_19
    '20': LABEL_20
    '21': LABEL_21
    '22': LABEL_22
    '23': LABEL_23
    '24': LABEL_24
    '25': LABEL_25
    '26': LABEL_26
    '27': LABEL_27
    '28': LABEL_28
    '29': LABEL_29
    '30': LABEL_30
    '31': LABEL_31
    '32': LABEL_32
    '33': LABEL_33
    '34': LABEL_34
    '35': LABEL_35
    '36': LABEL_36
    '37': LABEL_37
    '38': LABEL_38
    '39': LABEL_39
    '40': LABEL_40
    '41': LABEL_41
    '42': LABEL_42
    '43': LABEL_43
    '44': LABEL_44
    '45': LABEL_45
    '46': LABEL_46
    '47': LABEL_47
    '48': LABEL_48
    '49': LABEL_49
    '50': LABEL_50
    '51': LABEL_51
    '52': LABEL_52
    '53': LABEL_53
    '54': LABEL_54
    '55': LABEL_55
    '56': LABEL_56
    '57': LABEL_57
    '58': LABEL_58
    '59': LABEL_59
    '60': LABEL_60
    '61': LABEL_61
    '62': LABEL_62
    '63': LABEL_63
    '64': LABEL_64
    '65': LABEL_65
    '66': LABEL_66
    '67': LABEL_67
    '68': LABEL_68
    '69': LABEL_69
    '70': LABEL_70
    '71': LABEL_71
    '72': LABEL_72
    '73': LABEL_73
    '74': LABEL_74
    '75': LABEL_75
    '76': LABEL_76
    '77': LABEL_77
    '78': LABEL_78
    '79': LABEL_79
    '80': LABEL_80
    '81': LABEL_81
    '82': LABEL_82
    '83': LABEL_83
    '84': LABEL_84
    '85': LABEL_85
    '86': LABEL_86
    '87': LABEL_87
    '88': LABEL_88
    '89': LABEL_89
    '90': LABEL_90
    '91': LABEL_91
    '92': LABEL_92
    '93': LABEL_93
    '94': LABEL_94
    '95': LABEL_95
    '96': LABEL_96
    '97': LABEL_97
    '98': LABEL_98
    '99': LABEL_99
    '100': LABEL_100
    '101': LABEL_101
    '102': LABEL_102
    '103': LABEL_103
    '104': LABEL_104
    '105': LABEL_105
    '106': LABEL_106
    '107': LABEL_107
    '108': LABEL_108
    '109': LABEL_109
    '110': LABEL_110
    '111': LABEL_111
    '112': LABEL_112
    '113': LABEL_113
    '114': LABEL_114
    '115': LABEL_115
    '116': LABEL_116
    '117': LABEL_117
    '118': LABEL_118
    '119': LABEL_119
    '120': LABEL_120
    '121': LABEL_121
    '122': LABEL_122
    '123': LABEL_123
    '124': LABEL_124
    '125': LABEL_125
    '126': LABEL_126
    '127': LABEL_127
    '128': LABEL_128
    '129': LABEL_129
    '130': LABEL_130
    '131': LABEL_131
    '132': LABEL_132
    '133': LABEL_133
    '134': LABEL_134
    '135': LABEL_135
    '136': LABEL_136
    '137': LABEL_137
    '138': LABEL_138
    '139': LABEL_139
    '140': LABEL_140
    '141': LABEL_141
    '142': LABEL_142
    '143': LABEL_143
    '144': LABEL_144
    '145': LABEL_145
    '146': LABEL_146
    '147': LABEL_147
    '148': LABEL_148
    '149': LABEL_149
    '150': LABEL_150
    '151': LABEL_151
    '152': LABEL_152
    '153': LABEL_153
    '154': LABEL_154
    '155': LABEL_155
    '156': LABEL_156
    '157': LABEL_157
    '158': LABEL_158
    '159': LABEL_159
    '160': LABEL_160
    '161': LABEL_161
    '162': LABEL_162
    '163': LABEL_163
    '164': LABEL_164
    '165': LABEL_165
    '166': LABEL_166
    '167': LABEL_167
    '168': LABEL_168
    '169': LABEL_169
    '170': LABEL_170
    '171': LABEL_171
    '172': LABEL_172
    '173': LABEL_173
    '174': LABEL_174
    '175': LABEL_175
    '176': LABEL_176
    '177': LABEL_177
    '178': LABEL_178
    '179': LABEL_179
    '180': LABEL_180
    '181': LABEL_181
    '182': LABEL_182
    '183': LABEL_183
    '184': LABEL_184
    '185': LABEL_185
    '186': LABEL_186
    '187': LABEL_187
    '188': LABEL_188
    '189': LABEL_189
    '190': LABEL_190
    '191': LABEL_191
    '192': LABEL_192
    '193': LABEL_193
    '194': LABEL_194
    '195': LABEL_195
    '196': LABEL_196
    '197': LABEL_197
label2id:
  desc: null
  value:
    LABEL_0: 0
    LABEL_1: 1
    LABEL_2: 2
    LABEL_3: 3
    LABEL_4: 4
    LABEL_5: 5
    LABEL_6: 6
    LABEL_7: 7
    LABEL_8: 8
    LABEL_9: 9
    LABEL_10: 10
    LABEL_11: 11
    LABEL_12: 12
    LABEL_13: 13
    LABEL_14: 14
    LABEL_15: 15
    LABEL_16: 16
    LABEL_17: 17
    LABEL_18: 18
    LABEL_19: 19
    LABEL_20: 20
    LABEL_21: 21
    LABEL_22: 22
    LABEL_23: 23
    LABEL_24: 24
    LABEL_25: 25
    LABEL_26: 26
    LABEL_27: 27
    LABEL_28: 28
    LABEL_29: 29
    LABEL_30: 30
    LABEL_31: 31
    LABEL_32: 32
    LABEL_33: 33
    LABEL_34: 34
    LABEL_35: 35
    LABEL_36: 36
    LABEL_37: 37
    LABEL_38: 38
    LABEL_39: 39
    LABEL_40: 40
    LABEL_41: 41
    LABEL_42: 42
    LABEL_43: 43
    LABEL_44: 44
    LABEL_45: 45
    LABEL_46: 46
    LABEL_47: 47
    LABEL_48: 48
    LABEL_49: 49
    LABEL_50: 50
    LABEL_51: 51
    LABEL_52: 52
    LABEL_53: 53
    LABEL_54: 54
    LABEL_55: 55
    LABEL_56: 56
    LABEL_57: 57
    LABEL_58: 58
    LABEL_59: 59
    LABEL_60: 60
    LABEL_61: 61
    LABEL_62: 62
    LABEL_63: 63
    LABEL_64: 64
    LABEL_65: 65
    LABEL_66: 66
    LABEL_67: 67
    LABEL_68: 68
    LABEL_69: 69
    LABEL_70: 70
    LABEL_71: 71
    LABEL_72: 72
    LABEL_73: 73
    LABEL_74: 74
    LABEL_75: 75
    LABEL_76: 76
    LABEL_77: 77
    LABEL_78: 78
    LABEL_79: 79
    LABEL_80: 80
    LABEL_81: 81
    LABEL_82: 82
    LABEL_83: 83
    LABEL_84: 84
    LABEL_85: 85
    LABEL_86: 86
    LABEL_87: 87
    LABEL_88: 88
    LABEL_89: 89
    LABEL_90: 90
    LABEL_91: 91
    LABEL_92: 92
    LABEL_93: 93
    LABEL_94: 94
    LABEL_95: 95
    LABEL_96: 96
    LABEL_97: 97
    LABEL_98: 98
    LABEL_99: 99
    LABEL_100: 100
    LABEL_101: 101
    LABEL_102: 102
    LABEL_103: 103
    LABEL_104: 104
    LABEL_105: 105
    LABEL_106: 106
    LABEL_107: 107
    LABEL_108: 108
    LABEL_109: 109
    LABEL_110: 110
    LABEL_111: 111
    LABEL_112: 112
    LABEL_113: 113
    LABEL_114: 114
    LABEL_115: 115
    LABEL_116: 116
    LABEL_117: 117
    LABEL_118: 118
    LABEL_119: 119
    LABEL_120: 120
    LABEL_121: 121
    LABEL_122: 122
    LABEL_123: 123
    LABEL_124: 124
    LABEL_125: 125
    LABEL_126: 126
    LABEL_127: 127
    LABEL_128: 128
    LABEL_129: 129
    LABEL_130: 130
    LABEL_131: 131
    LABEL_132: 132
    LABEL_133: 133
    LABEL_134: 134
    LABEL_135: 135
    LABEL_136: 136
    LABEL_137: 137
    LABEL_138: 138
    LABEL_139: 139
    LABEL_140: 140
    LABEL_141: 141
    LABEL_142: 142
    LABEL_143: 143
    LABEL_144: 144
    LABEL_145: 145
    LABEL_146: 146
    LABEL_147: 147
    LABEL_148: 148
    LABEL_149: 149
    LABEL_150: 150
    LABEL_151: 151
    LABEL_152: 152
    LABEL_153: 153
    LABEL_154: 154
    LABEL_155: 155
    LABEL_156: 156
    LABEL_157: 157
    LABEL_158: 158
    LABEL_159: 159
    LABEL_160: 160
    LABEL_161: 161
    LABEL_162: 162
    LABEL_163: 163
    LABEL_164: 164
    LABEL_165: 165
    LABEL_166: 166
    LABEL_167: 167
    LABEL_168: 168
    LABEL_169: 169
    LABEL_170: 170
    LABEL_171: 171
    LABEL_172: 172
    LABEL_173: 173
    LABEL_174: 174
    LABEL_175: 175
    LABEL_176: 176
    LABEL_177: 177
    LABEL_178: 178
    LABEL_179: 179
    LABEL_180: 180
    LABEL_181: 181
    LABEL_182: 182
    LABEL_183: 183
    LABEL_184: 184
    LABEL_185: 185
    LABEL_186: 186
    LABEL_187: 187
    LABEL_188: 188
    LABEL_189: 189
    LABEL_190: 190
    LABEL_191: 191
    LABEL_192: 192
    LABEL_193: 193
    LABEL_194: 194
    LABEL_195: 195
    LABEL_196: 196
    LABEL_197: 197
tokenizer_class:
  desc: null
  value: null
prefix:
  desc: null
  value: null
pad_token_id:
  desc: null
  value: null
sep_token_id:
  desc: null
  value: null
decoder_start_token_id:
  desc: null
  value: null
task_specific_params:
  desc: null
  value:
    text-generation:
      do_sample: true
      max_length: 50
problem_type:
  desc: null
  value: null
_name_or_path:
  desc: null
  value: distilgpt2
transformers_version:
  desc: null
  value: 4.30.0
_num_labels:
  desc: null
  value: 1
model_type:
  desc: null
  value: gpt2
n_ctx:
  desc: null
  value: 1024
output_dir:
  desc: null
  value: ./results
overwrite_output_dir:
  desc: null
  value: false
do_train:
  desc: null
  value: false
do_eval:
  desc: null
  value: true
do_predict:
  desc: null
  value: false
evaluation_strategy:
  desc: null
  value: epoch
prediction_loss_only:
  desc: null
  value: false
per_device_train_batch_size:
  desc: null
  value: 4
per_device_eval_batch_size:
  desc: null
  value: 4
per_gpu_train_batch_size:
  desc: null
  value: None
per_gpu_eval_batch_size:
  desc: null
  value: None
gradient_accumulation_steps:
  desc: null
  value: 1
eval_accumulation_steps:
  desc: null
  value: None
eval_delay:
  desc: null
  value: 0
learning_rate:
  desc: null
  value: 5.0e-05
weight_decay:
  desc: null
  value: 0.01
adam_beta1:
  desc: null
  value: 0.9
adam_beta2:
  desc: null
  value: 0.999
adam_epsilon:
  desc: null
  value: 1.0e-08
max_grad_norm:
  desc: null
  value: 1.0
num_train_epochs:
  desc: null
  value: 3
max_steps:
  desc: null
  value: -1
lr_scheduler_type:
  desc: null
  value: linear
warmup_ratio:
  desc: null
  value: 0.0
warmup_steps:
  desc: null
  value: 500
log_level:
  desc: null
  value: passive
log_level_replica:
  desc: null
  value: warning
log_on_each_node:
  desc: null
  value: true
logging_dir:
  desc: null
  value: ./logs
logging_strategy:
  desc: null
  value: steps
logging_first_step:
  desc: null
  value: false
logging_steps:
  desc: null
  value: 500
logging_nan_inf_filter:
  desc: null
  value: true
save_strategy:
  desc: null
  value: steps
save_steps:
  desc: null
  value: 500
save_total_limit:
  desc: null
  value: None
save_safetensors:
  desc: null
  value: false
save_on_each_node:
  desc: null
  value: false
no_cuda:
  desc: null
  value: false
use_mps_device:
  desc: null
  value: false
seed:
  desc: null
  value: 42
data_seed:
  desc: null
  value: None
jit_mode_eval:
  desc: null
  value: false
use_ipex:
  desc: null
  value: false
bf16:
  desc: null
  value: false
fp16:
  desc: null
  value: false
fp16_opt_level:
  desc: null
  value: O1
half_precision_backend:
  desc: null
  value: auto
bf16_full_eval:
  desc: null
  value: false
fp16_full_eval:
  desc: null
  value: false
tf32:
  desc: null
  value: None
local_rank:
  desc: null
  value: 0
ddp_backend:
  desc: null
  value: None
tpu_num_cores:
  desc: null
  value: None
tpu_metrics_debug:
  desc: null
  value: false
debug:
  desc: null
  value: '[]'
dataloader_drop_last:
  desc: null
  value: false
eval_steps:
  desc: null
  value: None
dataloader_num_workers:
  desc: null
  value: 0
past_index:
  desc: null
  value: -1
run_name:
  desc: null
  value: ./results
disable_tqdm:
  desc: null
  value: true
remove_unused_columns:
  desc: null
  value: true
label_names:
  desc: null
  value: None
load_best_model_at_end:
  desc: null
  value: false
metric_for_best_model:
  desc: null
  value: None
greater_is_better:
  desc: null
  value: None
ignore_data_skip:
  desc: null
  value: false
sharded_ddp:
  desc: null
  value: '[]'
fsdp:
  desc: null
  value: '[]'
fsdp_min_num_params:
  desc: null
  value: 0
fsdp_config:
  desc: null
  value: '{''fsdp_min_num_params'': 0, ''xla'': False, ''xla_fsdp_grad_ckpt'': False}'
fsdp_transformer_layer_cls_to_wrap:
  desc: null
  value: None
deepspeed:
  desc: null
  value: None
label_smoothing_factor:
  desc: null
  value: 0.0
optim:
  desc: null
  value: adamw_hf
optim_args:
  desc: null
  value: None
adafactor:
  desc: null
  value: false
group_by_length:
  desc: null
  value: false
length_column_name:
  desc: null
  value: length
report_to:
  desc: null
  value: '[''tensorboard'', ''wandb'']'
ddp_find_unused_parameters:
  desc: null
  value: None
ddp_bucket_cap_mb:
  desc: null
  value: None
dataloader_pin_memory:
  desc: null
  value: true
skip_memory_metrics:
  desc: null
  value: true
use_legacy_prediction_loop:
  desc: null
  value: false
push_to_hub:
  desc: null
  value: false
resume_from_checkpoint:
  desc: null
  value: None
hub_model_id:
  desc: null
  value: None
hub_strategy:
  desc: null
  value: every_save
hub_token:
  desc: null
  value: <HUB_TOKEN>
hub_private_repo:
  desc: null
  value: false
gradient_checkpointing:
  desc: null
  value: false
include_inputs_for_metrics:
  desc: null
  value: false
fp16_backend:
  desc: null
  value: auto
push_to_hub_model_id:
  desc: null
  value: None
push_to_hub_organization:
  desc: null
  value: None
push_to_hub_token:
  desc: null
  value: <PUSH_TO_HUB_TOKEN>
mp_parameters:
  desc: null
  value: ''
auto_find_batch_size:
  desc: null
  value: false
full_determinism:
  desc: null
  value: false
torchdynamo:
  desc: null
  value: None
ray_scope:
  desc: null
  value: last
ddp_timeout:
  desc: null
  value: 1800
torch_compile:
  desc: null
  value: false
torch_compile_backend:
  desc: null
  value: None
torch_compile_mode:
  desc: null
  value: None
xpu_backend:
  desc: null
  value: None
train_batch_size:
  desc: null
  value: 4
eval_batch_size:
  desc: null
  value: 4
