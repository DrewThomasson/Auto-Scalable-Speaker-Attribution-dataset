The `quotes+contentAroundQuotes.py` file will use the booknlp outputs to print out all of the quotes found in the book as well as specified content around the quotes up to a amount of tokens in front and behind


The `quotes+whoSaidQuote+contentAroundQuotes.py` file will use the booknlp outputs to do everythign the program before did but ALSO will tell you who said each specified quotes 


The g_book folder is just a folder that contains the outputs of a booknlprun on a test bookk of guradians of gahhool but i think its just the first chapter anyway lol

The `bigbird.py` will train bigbird on the csv file named output.csv on the task of quotation attribution



current plans on how this model will me trained:

If you're planning to further train the BERT model, which has initially learned quotation attribution from BOOKNLP outputs, with additional data labeled by GPT-4, you are essentially engaging in a multi-stage training process that involves both knowledge distillation and fine-tuning with human-like labeled data.

1. **Knowledge Distillation:** The first stage, as previously described, where your BERT model learns from the outputs of BOOKNLP, distilling knowledge from it.

2. **Fine-Tuning with Enhanced Data:** The second stage involves further training or fine-tuning the model on quotation attribution data that has been labeled by GPT-4. Given GPT-4's capabilities in generating human-like text and understanding context, labels provided by GPT-4 could be highly nuanced and potentially superior in quality to straightforward labels. This stage aims to improve the BERT model's performance by leveraging high-quality, possibly more complex or nuanced, labeled data.

This process could be described as a hybrid approach, combining knowledge distillation with advanced fine-tuning. The idea is to first bootstrap the model's ability to understand and attribute quotations using the distilled knowledge from BOOKNLP and then refine and enhance its capabilities with rich, nuanced labels generated by an advanced model like GPT-4. The outcome is a specialized BERT model that is potentially better at quotation attribution than either of its teachers (BOOKNLP and the GPT-4-augmented labeling).

This approach leverages the strengths of both automated systems (BOOKNLP for initial knowledge and GPT-4 for depth and nuance in labeling) to create a model that excels at a specific task. It's a creative way to combine different AI technologies to achieve superior performance in specialized domains.
