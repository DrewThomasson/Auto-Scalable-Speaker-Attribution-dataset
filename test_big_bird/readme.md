The `quotes+contentAroundQuotes.py` file will use the booknlp outputs to print out all of the quotes found in the book as well as specified content around the quotes up to a amount of tokens in front and behind


The `quotes+whoSaidQuote+contentAroundQuotes.py` file will use the booknlp outputs to do everythign the program before did but ALSO will tell you who said each specified quotes 


The g_book folder is just a folder that contains the outputs of a booknlprun on a test bookk of guradians of gahhool but i think its just the first chapter anyway lol

The `bigbird.py` will train bigbird on the csv file named output.csv on the task of quotation attribution



current plans on how this model will me trained:

If you're planning to further train the BERT model, which has initially learned quotation attribution from BOOKNLP outputs, with additional data labeled by GPT-4, you are essentially engaging in a multi-stage training process that involves both knowledge distillation and fine-tuning with human-like labeled data.

1. **Knowledge Distillation:** The first stage, as previously described, where your BERT model learns from the outputs of BOOKNLP, distilling knowledge from it.

2. **Fine-Tuning with Enhanced Data:** The second stage involves further training or fine-tuning the model on quotation attribution data that has been labeled by GPT-4. Given GPT-4's capabilities in generating human-like text and understanding context, labels provided by GPT-4 could be highly nuanced and potentially superior in quality to straightforward labels. This stage aims to improve the BERT model's performance by leveraging high-quality, possibly more complex or nuanced, labeled data.

This process could be described as a hybrid approach, combining knowledge distillation with advanced fine-tuning. The idea is to first bootstrap the model's ability to understand and attribute quotations using the distilled knowledge from BOOKNLP and then refine and enhance its capabilities with rich, nuanced labels generated by an advanced model like GPT-4. The outcome is a specialized BERT model that is potentially better at quotation attribution than either of its teachers (BOOKNLP and the GPT-4-augmented labeling).

This approach leverages the strengths of both automated systems (BOOKNLP for initial knowledge and GPT-4 for depth and nuance in labeling) to create a model that excels at a specific task. It's a creative way to combine different AI technologies to achieve superior performance in specialized domains.




Update: when training the big bird model on the output.csv file with 20 steps I gotthe unpredicted result of generalization appearing in the model instead of overfitting????
LOG:
{'eval_loss': 2.8449819087982178, 'eval_accuracy': 0.5238095238095238, 'eval_runtime': 0.0735, 'eval_samples_per_second': 285.846, 'eval_steps_per_second': 27.223, 'epoch': 20.0}
{'train_runtime': 57.3258, 'train_samples_per_second': 63.846, 'train_steps_per_second': 8.024, 'train_loss': 3.162827612006146, 'epoch': 20.0}
100%|█████████████████████████████████████████████████████████████████████████████████| 460/460 [00:57<00:00,  8.02it/s]
100%|█████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 85.16it/s]
{'eval_loss': 2.8449819087982178, 'eval_accuracy': 0.5238095238095238, 'eval_runtime': 0.0733, 'eval_samples_per_second': 286.389, 'eval_steps_per_second': 27.275, 'epoch': 20.0}
100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1562.71it/s]
Text: During the intense chess tournament, a prodigy declared, 'Every move must be calculated with precision and foresight.' The grandmasters, spectators, and fellow competitors marveled at the young talent's strategic brilliance.
Predicted label: coach

Text: During the investor pitch, the startup founder stated, 'Our mission is to make a positive impact on society.' The investors were intrigued by the socially conscious approach.
Predicted label: founder

Text: During the brainstorming session, Lily proposed, 'What if we created a loyalty program to retain our customers?' Noah thought it could foster long-term relationships.
Predicted label: Liam

